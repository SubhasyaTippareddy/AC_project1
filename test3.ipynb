{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "path = 'FacialLandmarks/BU4DFE_BND_V1.1/'\n",
    "X=[]\n",
    "Y=[]\n",
    "# 101 faces - sub folders, 6 emotions - Angry, Disgust, Fear, Happy, Sad, Surprise\n",
    "for face_dir in os.listdir(path)[1:]:\n",
    "    face_path = path+face_dir+'/'\n",
    "    for label in os.listdir(face_path):\n",
    "        emotion_path = face_path+label+'/'\n",
    "        for file in os.listdir(emotion_path):\n",
    "            if file.endswith(\".bnd\") or file.endswith(\".landmark\"):\n",
    "                file_path = emotion_path+file\n",
    "                points = np.loadtxt(emotion_path+file, usecols=(1, 2, 3), encoding='utf-8') #x,y,z\n",
    "                X.append(points)\n",
    "                Y.append(label)\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X = X.reshape(X.shape[0], -1)               \n",
    "x_length = len(X)\n",
    "y_length = len(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import acos\n",
    "import math\n",
    "\n",
    "pi=round(2*acos(0.0), 3)\n",
    "\n",
    "def translate_data(X):\n",
    "    X_translated =[]\n",
    "    for face in X:\n",
    "        mean = np.mean(face,axis=0)\n",
    "        print(mean)\n",
    "        translated_face = face - mean\n",
    "        X_translated.append(translated_face)\n",
    "    X_translated = np.array(X_translated)\n",
    "    return X_translated\n",
    "\n",
    "def rotate_data(X, axis='x'):\n",
    "    sin_angle = math.sin(pi) #0\n",
    "    cos_angle = math.cos(pi) #-1\n",
    "    rotated_X=[]\n",
    "    rotated_face = []\n",
    "    if axis=='x':\n",
    "        for face in X:\n",
    "            for point in face:\n",
    "                rotated_face.append([point[0], cos_angle * point[1] - sin_angle * point[2], sin_angle * point[1] + cos_angle * point[2]])\n",
    "            rotated_X.append(rotated_face)\n",
    "    if axis=='y':\n",
    "        for face in X:\n",
    "            for point in face:\n",
    "                rotated_face.append([cos_angle * point[0] + sin_angle * point[2], point[1], -sin_angle * point[0] + cos_angle * point[2]])\n",
    "            rotated_X.append(rotated_face)\n",
    "    if axis=='z':\n",
    "        for face in X:\n",
    "            for point in face:\n",
    "                rotated_face.append([cos_angle * point[0] - sin_angle * point[1], sin_angle * point[0] + cos_angle * point[1], point[2]])\n",
    "            rotated_X.append(rotated_face)\n",
    "    else:\n",
    "        raise ValueError(\"Axis must be 'x', 'y', or 'z'\")\n",
    "    rotated_X=np.array(rotated_X)\n",
    "    return rotated_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def classification(X,Y, classifier_type='RF'):\n",
    "    # Select the classifier\n",
    "    if classifier_type == 'RF':\n",
    "        print(\"RF running\")\n",
    "        clf = RandomForestClassifier()\n",
    "    elif classifier_type == 'SVM':\n",
    "        clf = SVC()\n",
    "    elif classifier_type == 'TREE':\n",
    "        clf = DecisionTreeClassifier()\n",
    "\n",
    "  # Define the scoring metrics\n",
    "    scoring = ['accuracy', 'precision_macro', 'recall_macro']\n",
    "    Y_pred = []\n",
    "    test_indices = []\n",
    "    cv = StratifiedKFold(n_splits=10)\n",
    "    for (train,test) in cv.split(X,Y):\n",
    "        # print(train,test)\n",
    "        # print(len(train),len(test))\n",
    "        # print(X[train],Y[train])\n",
    "        clf.fit(X[train],Y[train])\n",
    "        Y_pred.append(clf.predict(X[test]))\n",
    "        test_indices.append(test)\n",
    "    \n",
    "    return Y,Y_pred,test_indices\n",
    "    # scores = cross_validate(clf, data, labels, cv=cv, scoring=scoring, return_train_score=False)\n",
    "\n",
    "    # # Since cross_validate returns a dictionary, you can process it however you need.\n",
    "    # # For example, to print the mean scores:\n",
    "    # for score_name, score_values in scores.items():\n",
    "    #     print(f\"{score_name}: {np.mean(score_values)}\")\n",
    "\n",
    "    # return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_original,y_prediction,testi = classification(np.array(X),np.array(Y),'TREE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def PrintEvalMetrics(pred, indices, y):\n",
    "    finalPredictions = []\n",
    "    groundTruth = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    accuracies = []\n",
    "    for array in indices:\n",
    "        temp=[]\n",
    "        for ele in array:\n",
    "            temp.append(y[ele])\n",
    "        groundTruth.append(temp)\n",
    "        #finalPredictions.extend(p)\n",
    "    for i in range(10):\n",
    "        print(confusion_matrix(pred[i],groundTruth[i]))\n",
    "        precisions.append(precision_score(groundTruth[i], pred[i], average='macro'))\n",
    "        recalls.append(recall_score(groundTruth[i], pred[i], average='macro'))\n",
    "        accuracies.append(accuracy_score(groundTruth[i], pred[i]))\n",
    "        # #print(pred[i],y[i])\n",
    "        # groundTruth.extend(y[i])\n",
    "    a = 0\n",
    "    for i in range(len(finalPredictions)):\n",
    "        if(finalPredictions[i]==groundTruth[i]):\n",
    "            a+=1\n",
    "    print(a)\n",
    "    #print(finalPredictions)\n",
    "    print(confusion_matrix(finalPredictions, groundTruth))\n",
    "    print(\"Precision: \", np.mean(np.array(precisions)))#precision_score(groundTruth, finalPredictions, average='macro'))\n",
    "    print(\"Recall: \", np.mean(np.array(recalls)))# recall_score(groundTruth, finalPredictions, average='macro'))\n",
    "    print(\"Accuracy: \", np.mean(np.array(accuracies)))# accuracy_score(groundTruth, finalPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[375 117 172 181 207  57]\n",
      " [ 81 216 193 220 114 237]\n",
      " [141 120 188 106 287 117]\n",
      " [ 90 265  59 140  59 137]\n",
      " [222  70 298 188 170  90]\n",
      " [104 229  94 163 177 368]]\n",
      "[[318  54 104  74 126  39]\n",
      " [ 28 231 110  32 139  80]\n",
      " [ 84 147 271 204 143 139]\n",
      " [148 149 234 452 189  53]\n",
      " [185 114  79  28 257  65]\n",
      " [250 322 206 208 160 630]]\n",
      "[[328  92 153 116  92  88]\n",
      " [137 357  96  66  68 161]\n",
      " [113 173 185 507 184 247]\n",
      " [112 194 204 183 365  92]\n",
      " [237  90 181  71 270  94]\n",
      " [ 86 111 185  54  36 323]]\n",
      "[[287 393 167 231 385 189]\n",
      " [123 307 435 174 190 288]\n",
      " [231  66 128  95 104  96]\n",
      " [238 102  88 364 114  96]\n",
      " [133  52  41  47  84   4]\n",
      " [  1  97 145  86 138 332]]\n",
      "[[451 203 273  95  87 116]\n",
      " [132 217 259  46 178  98]\n",
      " [ 82 139 178 219 167  65]\n",
      " [ 63 122 113 488 177  42]\n",
      " [170 190  89  34 132  55]\n",
      " [114 147  92 115 273 630]]\n",
      "[[357 162 363 342 307 163]\n",
      " [166 236 100  82  50 205]\n",
      " [107  45 181  97  88  28]\n",
      " [133 345 125 231 276  77]\n",
      " [160 156  25 152 223  42]\n",
      " [ 89  73 211  93  70 491]]\n",
      "[[298 153 105 170 181  50]\n",
      " [165 116 227 273 156 124]\n",
      " [157 173 157  99 251  87]\n",
      " [ 42  91 108 362  89  65]\n",
      " [142 240  54  22 113  38]\n",
      " [208 244 354  71 224 642]]\n",
      "[[350 353 121 275 293 255]\n",
      " [155 120  30 119   7  72]\n",
      " [120 174 185  47  19 179]\n",
      " [155 189  67 451 220  86]\n",
      " [ 66  16 152  26 298  72]\n",
      " [166 165 450  79 177 342]]\n",
      "[[149  74  42  73  62  23]\n",
      " [150 199 269 274 215  66]\n",
      " [118 124 201 159 171 170]\n",
      " [126 249 116 224  67  10]\n",
      " [ 79  81 208  13 316  39]\n",
      " [390 290 169 254 183 698]]\n",
      "[[400 106 146 351  56  28]\n",
      " [315 338 168 198  99  49]\n",
      " [ 70 199 268 133 126 169]\n",
      " [ 14  83  22 192 176 104]\n",
      " [210  57 201   5 419  24]\n",
      " [  3 234 199 119 138 632]]\n",
      "0\n",
      "Precision:  0.30139316724553755\n",
      "Recall:  0.2984610406702896\n",
      "Accuracy:  0.2982714016124016\n"
     ]
    }
   ],
   "source": [
    "PrintEvalMetrics(y_prediction,testi,y_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
