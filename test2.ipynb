{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "path = 'FacialLandmarks/BU4DFE_BND_V1.1/'\n",
    "X=[]\n",
    "Y=[]\n",
    "# 101 faces - sub folders, 6 emotions - Angry, Disgust, Fear, Happy, Sad, Surprise\n",
    "for face_dir in os.listdir(path)[1:]:\n",
    "    face_path = path+face_dir+'/'\n",
    "    for label in os.listdir(face_path):\n",
    "        emotion_path = face_path+label+'/'\n",
    "        for file in os.listdir(emotion_path):\n",
    "            if file.endswith(\".bnd\") or file.endswith(\".landmark\"):\n",
    "                file_path = emotion_path+file\n",
    "                points = np.loadtxt(emotion_path+file, usecols=(1, 2, 3), encoding='utf-8') #x,y,z\n",
    "                X.append(points)\n",
    "                Y.append(label)\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X = X.reshape(X.shape[0], -1)               \n",
    "x_length = len(X)\n",
    "y_length = len(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import acos\n",
    "import math\n",
    "\n",
    "pi=round(2*acos(0.0), 3)\n",
    "\n",
    "def translate_data(X):\n",
    "    X_translated =[]\n",
    "    for face in X:\n",
    "        mean = np.mean(face,axis=0)\n",
    "        print(mean)\n",
    "        translated_face = face - mean\n",
    "        X_translated.append(translated_face)\n",
    "    return X_translated\n",
    "\n",
    "def rotate_data(X, axis='x'):\n",
    "    sin_angle = math.sin(pi) #0\n",
    "    cos_angle = math.cos(pi) #-1\n",
    "    rotated_X=[]\n",
    "    rotated_face = []\n",
    "    if axis=='x':\n",
    "        for face in X:\n",
    "            for point in face:\n",
    "                rotated_face.append([point[0], cos_angle * point[1] - sin_angle * point[2], sin_angle * point[1] + cos_angle * point[2]])\n",
    "            rotated_X.append(rotated_face)\n",
    "    if axis=='y':\n",
    "        for face in X:\n",
    "            for point in face:\n",
    "                rotated_face.append([cos_angle * point[0] + sin_angle * point[2], point[1], -sin_angle * point[0] + cos_angle * point[2]])\n",
    "            rotated_X.append(rotated_face)\n",
    "    if axis=='z':\n",
    "        for face in X:\n",
    "            for point in face:\n",
    "                rotated_face.append([cos_angle * point[0] - sin_angle * point[1], sin_angle * point[0] + cos_angle * point[1], point[2]])\n",
    "            rotated_X.append(rotated_face)\n",
    "    else:\n",
    "        raise ValueError(\"Axis must be 'x', 'y', or 'z'\")\n",
    "    \n",
    "    return rotated_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_coord \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      2\u001b[0m y_coord \u001b[38;5;241m=\u001b[39m X[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      3\u001b[0m z_coord \u001b[38;5;241m=\u001b[39m X[:, \u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "x_coord = X[:, 0]\n",
    "y_coord = X[:, 1]\n",
    "z_coord = X[:, 2]\n",
    "trace = go.Scatter3d(\n",
    "    x=x_coord,\n",
    "    y=y_coord,\n",
    "    z=z_coord,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=12,\n",
    "        color=np.random.randn(100),  # You can use a colormap here\n",
    "        colorscale='Viridis'  # Or any other colormap from Plotly\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the layout\n",
    "layout = go.Layout(\n",
    "    title='3D Scatter Plot',\n",
    "    scene=dict(\n",
    "        xaxis_title='X-axis',\n",
    "        yaxis_title='Y-axis',\n",
    "        zaxis_title='Z-axis'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine and display\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def classification(X,Y, classifier_type='RF'):\n",
    "    # Select the classifier\n",
    "    if classifier_type == 'RF':\n",
    "        print(\"RF running\")\n",
    "        clf = RandomForestClassifier()\n",
    "    elif classifier_type == 'SVM':\n",
    "        clf = SVC()\n",
    "    elif classifier_type == 'TREE':\n",
    "        clf = DecisionTreeClassifier()\n",
    "\n",
    "  # Define the scoring metrics\n",
    "    scoring = ['accuracy', 'precision_macro', 'recall_macro']\n",
    "    Y_pred = []\n",
    "    test_indices = []\n",
    "    cv = StratifiedKFold(n_splits=10)\n",
    "    for (train,test) in cv.split(X,Y):\n",
    "        # print(train,test)\n",
    "        # print(len(train),len(test))\n",
    "        # print(X[train],Y[train])\n",
    "        clf.fit(X[train],Y[train])\n",
    "        Y_pred.append(clf.predict(X[test]))\n",
    "        test_indices.append(test)\n",
    "    \n",
    "    return Y,Y_pred,test_indices\n",
    "    # scores = cross_validate(clf, data, labels, cv=cv, scoring=scoring, return_train_score=False)\n",
    "\n",
    "    # # Since cross_validate returns a dictionary, you can process it however you need.\n",
    "    # # For example, to print the mean scores:\n",
    "    # for score_name, score_values in scores.items():\n",
    "    #     print(f\"{score_name}: {np.mean(score_values)}\")\n",
    "\n",
    "    # return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_original,y_prediction,testi = classification(np.array(X),np.array(Y),'TREE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def PrintEvalMetrics(pred, indices, y):\n",
    "    finalPredictions = []\n",
    "    groundTruth = []\n",
    "    for p in pred:\n",
    "        finalPredictions.extend(p)\n",
    "    for i in indices:\n",
    "        groundTruth.extend(y[i])\n",
    "    print(confusion_matrix(finalPredictions, groundTruth))\n",
    "    print(\"Precision: \", precision_score(groundTruth, finalPredictions, average='macro'))\n",
    "    print(\"Recall: \", recall_score(groundTruth, finalPredictions, average='macro'))\n",
    "    print(\"Accuracy: \" , accuracy_score(groundTruth, finalPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2914 1659 1525 1567 1584 1078]\n",
      " [1849 2551 1752 1994 1536 1426]\n",
      " [1585 1300 1945 1545 1390 1266]\n",
      " [ 964 1965 1210 3158 1726  705]\n",
      " [1524 1093 1392  758 2412  752]\n",
      " [1288 1603 2220  951 1494 4831]]\n",
      "Precision:  0.2909925296987809\n",
      "Recall:  0.29451367273026496\n",
      "Accuracy:  0.294338313061872\n"
     ]
    }
   ],
   "source": [
    "PrintEvalMetrics(y_prediction,testi,y_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60512"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6052,)\n"
     ]
    }
   ],
   "source": [
    "print(y_prediction[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
